<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>Python Pipelines for Sentiment Analysis</title>
  <meta name="description" content="Originally posted on ">

  <!-- CSS -->
  <link rel="stylesheet" href="/css/main.css">
  <link rel="stylesheet" href="/css/global.css">

  <!-- JS -->
  <script type="text/javascript" src="/MathJax/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
  <!-- script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script -->

  <link rel="canonical" href="http://xstatic.chewning.co/sklearn/2016/07/19/python-semantic.html">
  <link rel="alternate" type="application/rss+xml" title="chewning.co" href="http://xstatic.chewning.co/feed.xml">
</head>


  <body>

    <header class="site-header">

  <div class="wrapper">

    <!-- a class="site-title" href="/">chewning.co</a -->

    <nav class="site-nav">
      <a href="#" class="menu-icon">
        <svg viewBox="0 0 18 15">
          <path fill="#424242" d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.031C17.335,0,18,0.665,18,1.484L18,1.484z"/>
          <path fill="#424242" d="M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0c0-0.82,0.665-1.484,1.484-1.484 h15.031C17.335,6.031,18,6.696,18,7.516L18,7.516z"/>
          <path fill="#424242" d="M18,13.516C18,14.335,17.335,15,16.516,15H1.484C0.665,15,0,14.335,0,13.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.031C17.335,12.031,18,12.696,18,13.516L18,13.516z"/>
        </svg>
      </a>

      <div class="trigger">
          <a class="page-link" href="/index.html">&raquo; chewning.co</a> |
        
          
          <a class="page-link" href="/about/">about</a>
          
        
          
        
          
        
          
        
      </div>
    </nav>

  </div>

</header>


    <div class="page-content">
      <div class="wrapper">
        <article class="post" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title" itemprop="name headline">Python Pipelines for Sentiment Analysis</h1>
    <p class="post-meta"><time datetime="2016-07-19T00:28:57-04:00" itemprop="datePublished">07.19.16</time></p>
  </header>

  <div class="post-content" itemprop="articleBody">
    <h3 style="text-align: center;" id="originally-posted-on-a-hrefhttpsbloganswrcom20160718python-pipelines-for-sentiment-analysisimg-srcimagesanswrpng-a">Originally posted on <a href="https://blog.answr.com/2016/07/18/python-pipelines-for-sentiment-analysis/"><img src="/images/answr.png" /></a></h3>

<hr />
<hr />

<p><br />
How many times have you written boilerplate code that transforms your
data for input into an algorithm? Or maybe you are doing preliminary
testing on multiple types of models to test their performance. Python’s
scikit-learn offers an easy way to set up work-flows through their
Pipeline interface, which can greatly simplify data transformation and
model set up. Let’s take a look at some data and see how this can be
implemented in practice.</p>

<h3 id="sentiment-data">Sentiment Data</h3>
<div align="center">
  <img src="/images/smiley.jpg" />
</div>

<p>In there era of social media and brand reputation management, knowing
the sentiment of your user base relative to your product is vitally
important. Do you have insight into how much people approve of your
product? Kaggle hosts data science competitions and is a great place to
pick up new data for all sorts of problem domains and today we will take
at the Rotten Tomatoes dataset which we will use to create some models
to predict user sentiment. This data is comprised of phrases from movie
reviews that are labeled on a scale ranging from zero to four where zero
indicates a negative review and four indicates a positive review. For
your own projects you can either get publicly available data like this
to train on or you can use manually labeled data, like Tweets, specific
to your particular product. The benefit of using your own data is that
the vocabulary will be more specific to your problem domain. On the
other hand, you will need to invest time manually labeling the sentiment
your data.</p>

<p>We first need to load our data, so here is a helper function so that we
can start training.</p>

<div class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>

<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">cross_validation</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">random_projection</span>
<span class="kn">from</span> <span class="nn">sklearn.decomposition</span> <span class="kn">import</span> <span class="n">TruncatedSVD</span>
<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">VotingClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.feature_extraction.text</span> <span class="kn">import</span> <span class="n">CountVectorizer</span><span class="p">,</span> <span class="n">TfidfTransformer</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>
<span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">Pipeline</span>

<span class="k">def</span> <span class="nf">load_data</span><span class="p">(</span><span class="n">coarse</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">):</span>
    <span class="n">x</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">y</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">record</span> <span class="ow">in</span> <span class="nb">open</span><span class="p">(</span><span class="s">&#39;./data/train.tsv&#39;</span><span class="p">):</span>
        <span class="n">atoms</span> <span class="o">=</span> <span class="n">record</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s">&#39;</span><span class="se">\t</span><span class="s">&#39;</span><span class="p">)</span>
        <span class="n">sentiment</span> <span class="o">=</span> <span class="n">atoms</span><span class="p">[</span><span class="mi">3</span><span class="p">][:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="c"># skip header</span>
        <span class="k">if</span> <span class="n">sentiment</span> <span class="o">==</span> <span class="s">&#39;Sentiment&#39;</span><span class="p">:</span> <span class="k">continue</span>
        <span class="n">sentiment</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">sentiment</span><span class="p">)</span>
        <span class="n">pos</span> <span class="o">=</span> <span class="n">sentiment</span>
        <span class="k">if</span> <span class="n">coarse</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">sentiment</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span> <span class="k">continue</span>
            <span class="n">pos</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">sentiment</span> <span class="o">&gt;</span> <span class="mi">2</span><span class="p">)</span>
        <span class="n">x</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">atoms</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">lower</span><span class="p">())</span>
        <span class="n">y</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">pos</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">shuffle</span><span class="p">:</span>
            <span class="n">perm</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">permutation</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">)))</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="p">((</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">x</span><span class="p">)[</span><span class="n">perm</span><span class="p">])</span><span class="o">.</span><span class="n">tolist</span><span class="p">(),</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">y</span><span class="p">)[</span><span class="n">perm</span><span class="p">])</span><span class="o">.</span><span class="n">tolist</span><span class="p">())</span>
    <span class="k">return</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span></code></pre></div>

<p>This simply returns a tuple of training data and its associated class
label, i.e. it’s sentiment. The coarse parameter will be explained
later.</p>

<h3 id="pipelines">Pipelines</h3>

<p>The input into our model is raw text. We will be using a logistic
regression to classify each phrase, but logistic regression requires
that inputs be numeric and not text. We run the data through two
transformations, CountVectorizer and TfidfTransformer in order to
accommodate for this. The former provides word counts for each phrase
and the latter is a transformation of the word counts to penalize very
common words, giving more priority to “content” words.</p>

<div class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">load_data</span><span class="p">(</span><span class="n">coarse</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

<span class="n">count_vectorizer</span> <span class="o">=</span> <span class="n">CountVectorizer</span><span class="p">()</span>
<span class="n">tfidf</span> <span class="o">=</span> <span class="n">TfidfTransformer</span><span class="p">()</span>
<span class="n">logistic_regression</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">()</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([(</span><span class="s">&#39;counts&#39;</span><span class="p">,</span> <span class="n">count_vectorizer</span><span class="p">),</span>
                  <span class="p">(</span><span class="s">&#39;tfidf&#39;</span><span class="p">,</span> <span class="n">tfidf</span><span class="p">),</span>
                  <span class="p">(</span><span class="s">&#39;regression&#39;</span><span class="p">,</span> <span class="n">logistic_regression</span><span class="p">),</span> <span class="p">])</span>

<span class="n">scores</span> <span class="o">=</span> <span class="n">cross_validation</span><span class="o">.</span><span class="n">cross_val_score</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s">&#39;accuracy&#39;</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">&#39;Accuracy: </span><span class="si">%0.2f</span><span class="s">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">scores</span><span class="o">.</span><span class="n">mean</span><span class="p">()))</span>

<span class="c"># Accuracy: 0.63</span></code></pre></div>

<p>Accuracy is 63%. On the surface of it, that does not sound that
good. Looking into the Kaggle forums for this competition it looks
like a reasonable baseline is around 61% and many people initially
get around 56%. Given that we used all of the default settings for
the models and the only preprocessing was to lowercase the data, 63%
is not that bad. Random guessing would give an accuracy of 20%. This
is granular scale, however. We may have classified the review as a
4 instead of a 3. Both are on the positive side of the scale so the
accuracy may look a little worse than it is. A common thing to do is
to remove the neutral reviews and categorize the remaining either as
positive or negative sentiment. This is what the coarse parameter does
on the data load. Let’s see what that looks like.</p>

<div class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">load_data</span><span class="p">(</span><span class="n">coarse</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="n">count_vectorizer</span> <span class="o">=</span> <span class="n">CountVectorizer</span><span class="p">(</span><span class="n">lowercase</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">rp</span> <span class="o">=</span> <span class="n">random_projection</span><span class="o">.</span><span class="n">SparseRandomProjection</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">11</span><span class="p">)</span>
<span class="n">svd</span> <span class="o">=</span> <span class="n">TruncatedSVD</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">2500</span><span class="p">)</span>
<span class="n">tfidf</span> <span class="o">=</span> <span class="n">TfidfTransformer</span><span class="p">()</span>
<span class="n">logistic_regression</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">()</span>

<span class="n">model1</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([(</span><span class="s">&#39;counts&#39;</span><span class="p">,</span> <span class="n">count_vectorizer</span><span class="p">),</span>
                   <span class="p">(</span><span class="s">&#39;rand_proj&#39;</span><span class="p">,</span> <span class="n">rp</span><span class="p">),</span>
                   <span class="p">(</span><span class="s">&#39;logistic&#39;</span><span class="p">,</span> <span class="n">logistic_regression</span><span class="p">),</span> <span class="p">])</span>
<span class="n">model2</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([(</span><span class="s">&#39;counts&#39;</span><span class="p">,</span> <span class="n">count_vectorizer</span><span class="p">),</span>
                   <span class="p">(</span><span class="s">&#39;svd&#39;</span><span class="p">,</span> <span class="n">svd</span><span class="p">),</span>
                   <span class="p">(</span><span class="s">&#39;regression&#39;</span><span class="p">,</span> <span class="n">logistic_regression</span><span class="p">),</span> <span class="p">])</span>
<span class="n">model3</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([(</span><span class="s">&#39;counts&#39;</span><span class="p">,</span> <span class="n">count_vectorizer</span><span class="p">),</span>
                   <span class="p">(</span><span class="s">&#39;tfidf&#39;</span><span class="p">,</span> <span class="n">tfidf</span><span class="p">),</span>
                   <span class="p">(</span><span class="s">&#39;regression&#39;</span><span class="p">,</span> <span class="n">logistic_regression</span><span class="p">),</span> <span class="p">])</span>

<span class="n">vc</span> <span class="o">=</span> <span class="n">VotingClassifier</span><span class="p">(</span><span class="n">estimators</span><span class="o">=</span><span class="p">[(</span><span class="s">&#39;model1&#39;</span><span class="p">,</span> <span class="n">model1</span><span class="p">),</span> <span class="p">(</span><span class="s">&#39;model2&#39;</span><span class="p">,</span> <span class="n">model2</span><span class="p">),</span> <span class="p">(</span><span class="s">&#39;model3&#39;</span><span class="p">,</span> <span class="n">model3</span><span class="p">)],</span> 
                      <span class="n">voting</span><span class="o">=</span><span class="s">&#39;hard&#39;</span><span class="p">)</span>

<span class="k">for</span> <span class="n">clf</span><span class="p">,</span> <span class="n">label</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">([</span><span class="n">model1</span><span class="p">,</span> <span class="n">model2</span><span class="p">,</span> <span class="n">model3</span><span class="p">,</span> <span class="n">vc</span><span class="p">],</span> 
                      <span class="p">[</span><span class="s">&#39;model1_random_projections&#39;</span><span class="p">,</span> <span class="s">&#39;model2_svd&#39;</span><span class="p">,</span> <span class="s">&#39;model3_tfidf&#39;</span><span class="p">,</span> <span class="s">&#39;ensemble&#39;</span><span class="p">]):</span>
    <span class="n">scores</span> <span class="o">=</span> <span class="n">cross_validation</span><span class="o">.</span><span class="n">cross_val_score</span><span class="p">(</span><span class="n">clf</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s">&#39;accuracy&#39;</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s">&quot;Accuracy </span><span class="si">%s</span><span class="s">: </span><span class="si">%0.2f</span><span class="s">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">label</span><span class="p">,</span> <span class="n">scores</span><span class="o">.</span><span class="n">mean</span><span class="p">()))</span>

<span class="c"># Accuracy model1_random_projections: 0.85</span>
<span class="c"># Accuracy model2_svd: 0.81</span>
<span class="c"># Accuracy model3_tfidf: 0.86</span>
<span class="c"># Accuracy ensemble: 0.85</span></code></pre></div>

<p>What is going on here? We loaded the data and trained on binary
positive/negative output classes. We then set up a series of models
utilizing different data transformations: random projections, singular
value decomposition (SVD), and term frequency-inverse document frequency
(TF-IDF). The first two models utilize dimensionality reduction
techniques. The third uses TF-IDF, which was used in first, granular
model. The last output here is an ensemble (mixture) of all three models
where we use a max vote for the classification. Ensembles are typically
used for averaging different types of models. For this ensemble we used
the same model but leveraged different data transformations. It is more
common that ensembles used a mixture of different types of models (see
possible alternatives in the next section), but both paths are worth
exploring. It is interesting to note that the model with the highest
accuracy is the TF-IDF model. Many times it is well worth doing simple
things first and than trying more complex transformations. The accuracy of
the model is around 85%, given further tweaking of the model parameters
and data preprocessing we could probably get another 5% increase.</p>

<h3 id="enhancements">Enhancements</h3>

<p>As stated, we used many of the default parameters of the models. Here are
a few things you could try on your own to further increase the accuracy.</p>

<ul>
  <li>document preprocessing
    <ul>
      <li>bi-grams</li>
      <li>tokenizing</li>
      <li>stop word removal</li>
      <li>stemming</li>
    </ul>
  </li>
  <li>try different dimensionality reductions for SVD and random projections, i.e. reduce to a k-dimensional dataset</li>
  <li>optimizing the parameters of the logistic regression, e.g. regularization and solvers</li>
  <li>try different ensemble methods provided by scikit-learn</li>
  <li>try other models other than logistic regression, e.g. Naive Bayes or Support Vector Machines</li>
</ul>

<h3 id="conclusion">Conclusion</h3>

<p>We took a look at Pipelines in scikit-learn and how these can be used
to assemble models. We took two views in the data classification,
granular and coarse, and fit a few different models. The motivation was
to simplify boilerplate code and to afford the opportunity to easily
swap out different models. We also took a look at simple ensembles and
how these could be used in your work.</p>

<div id="disqus_thread"></div>
<script>
    /**
     *  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
     *  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables
     */
    /*
    var disqus_config = function () {
        this.page.url = 'http://chewning.co';
        this.page.identifier = 'pipelines_for_sentiment';
    };
    */
    (function() {  // DON'T EDIT BELOW THIS LINE
        var d = document, s = d.createElement('script');

        s.src = '//chewning.disqus.com/embed.js';

        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>

<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>


  </div>

</article>

      </div>
    </div>

    <footer class="site-footer">
    <div align="center" class="footer-text">
    This site is built from <a href="https://github.com/jekyll/jekyll">jekyll</a>.
    </div>
<!--
  <div class="wrapper">

    <h2 class="footer-heading">chewning.co</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li>chewning.co</li>
          <li><a href="mailto:"></a></li>
        </ul>
      </div>

      <div class="footer-col footer-col-2">
        <ul class="social-media-list">
          
          <li>
            <a href="https://github.com/init-random"><span class="icon icon--github"><svg viewBox="0 0 16 16"><path fill="#828282" d="M7.999,0.431c-4.285,0-7.76,3.474-7.76,7.761 c0,3.428,2.223,6.337,5.307,7.363c0.388,0.071,0.53-0.168,0.53-0.374c0-0.184-0.007-0.672-0.01-1.32 c-2.159,0.469-2.614-1.04-2.614-1.04c-0.353-0.896-0.862-1.135-0.862-1.135c-0.705-0.481,0.053-0.472,0.053-0.472 c0.779,0.055,1.189,0.8,1.189,0.8c0.692,1.186,1.816,0.843,2.258,0.645c0.071-0.502,0.271-0.843,0.493-1.037 C4.86,11.425,3.049,10.76,3.049,7.786c0-0.847,0.302-1.54,0.799-2.082C3.768,5.507,3.501,4.718,3.924,3.65 c0,0,0.652-0.209,2.134,0.796C6.677,4.273,7.34,4.187,8,4.184c0.659,0.003,1.323,0.089,1.943,0.261 c1.482-1.004,2.132-0.796,2.132-0.796c0.423,1.068,0.157,1.857,0.077,2.054c0.497,0.542,0.798,1.235,0.798,2.082 c0,2.981-1.814,3.637-3.543,3.829c0.279,0.24,0.527,0.713,0.527,1.437c0,1.037-0.01,1.874-0.01,2.129 c0,0.208,0.14,0.449,0.534,0.373c3.081-1.028,5.302-3.935,5.302-7.362C15.76,3.906,12.285,0.431,7.999,0.431z"/></svg>
</span><span class="username">init-random</span></a>

          </li>
          

          
          <li>
            <a href="https://twitter.com/keithchewning"><span class="icon icon--twitter"><svg viewBox="0 0 16 16"><path fill="#828282" d="M15.969,3.058c-0.586,0.26-1.217,0.436-1.878,0.515c0.675-0.405,1.194-1.045,1.438-1.809c-0.632,0.375-1.332,0.647-2.076,0.793c-0.596-0.636-1.446-1.033-2.387-1.033c-1.806,0-3.27,1.464-3.27,3.27 c0,0.256,0.029,0.506,0.085,0.745C5.163,5.404,2.753,4.102,1.14,2.124C0.859,2.607,0.698,3.168,0.698,3.767 c0,1.134,0.577,2.135,1.455,2.722C1.616,6.472,1.112,6.325,0.671,6.08c0,0.014,0,0.027,0,0.041c0,1.584,1.127,2.906,2.623,3.206 C3.02,9.402,2.731,9.442,2.433,9.442c-0.211,0-0.416-0.021-0.615-0.059c0.416,1.299,1.624,2.245,3.055,2.271 c-1.119,0.877-2.529,1.4-4.061,1.4c-0.264,0-0.524-0.015-0.78-0.046c1.447,0.928,3.166,1.469,5.013,1.469 c6.015,0,9.304-4.983,9.304-9.304c0-0.142-0.003-0.283-0.009-0.423C14.976,4.29,15.531,3.714,15.969,3.058z"/></svg>
</span><span class="username">keithchewning</span></a>

          </li>
          
        </ul>
      </div>

      <div class="footer-col footer-col-3">
        <p>Write an awesome description for your new site here. You can edit this line in _config.yml. It will appear in your document head meta (for Google search results) and in your feed.xml site description.
</p>
      </div>
    </div>

  </div>
-->
</footer>


  </body>

</html>
